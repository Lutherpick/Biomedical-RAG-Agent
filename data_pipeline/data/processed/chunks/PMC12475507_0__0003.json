{"doc_id": "PMC12475507_0", "chunk_index": 3, "chunk_total": null, "text": "the 5 h of the Hyper ‐ acute phase were fed into the EEGNet model for binary classification ( stroke vs . healthy ) . A 7 ‐ fold cross ‐ validation [ 24 ] was employed , where one mouse dataset was used as the test set and the remaining six as the training set . This process was repeated for each mouse , and the results were averaged across all seven experiments ( Figure 2 ) . Subsequently , EEG data were divided into six distinct time intervals for the same analysis : the first 30 min and consecutive hourly periods extending through the fifth hour . The models were implemented in PyTorch , running on an AMD CPU ( R9 ‐ 3950X , 3 . 5 GHz ) and an NVIDIA GPU ( RTX 3090 ) . The Adam optimizer with a learning rate of 0 . 001 was used to optimize the model ' s performance . Research methodology flowchart . The diagram illustrates the sequential steps of the experimental pipeline . First , raw EEG data is acquired from mice during the hyper ‐ acute stroke phase . The data undergoes preprocessing , including band ‐ pass filtering ( 1 – 40 Hz ) , downsampling to 256 Hz , and segmentation into 5 ‐ s epochs . These processed EEG segments are then used as input to the EEGNet model for binary classification ( stroke vs . healthy ) . A 7 ‐ fold cross ‐ validation strategy is applied to evaluate model performance . The integration of the preprocessing pipeline with the EEGNet architecture enables automated feature extraction and robust classification of stroke ‐ related EEG patterns . Model performance was evaluated using the following metrics : 1 . Accuracy ( Acc ) : indicates the percentage of correct predictions of the model on the test set . This metric can help determine the overall performance of the model ; TP ( True Positives ) : True cases , which are predicted to be positive and are actually positive ; FP ( False Positives ) : False positives , which are predicted to be positive but are actually negative ; FN ( false Negatives ) : False Negatives , which are predicted to be negative but are actually positive ; TN ( True Negatives ) : True Negatives , which are predicted to be negative but are actually negative . The higher the value , the better the model ' s classification results . Acc = TP + TNTP + FP + FN + TN 2 . Precision : the proportion of correct predictions in samples where the prediction is positive , based on the prediction results . The higher the precision rate , the more reliable the results . Precision rate can be expressed by the formula . Precision = TPTP + FP 3 . Recall : the proportion of correctly predicted positive cases out of the total number of actual positive cases , based on the actual samples . The higher the recall , the fewer positive cases are missed by the model . Recall = TPTP + FN 4 . F1 Score : as a statistical metric to measure the balance between precision and recall of a binary classification model . A higher F1 score implies a higher precision and recall of the model , which is usually considered a sign of better model performance . F1 = 2 × Precision × RecallPrecision + Recall 5 . ROC Curve and AUC : the Receiver Operating Characteristic ( ROC ) curve"}