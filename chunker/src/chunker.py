from langchain_experimental import text_splitter

from langchain_huggingface import HuggingFaceEmbeddings
from typing import List

from huggingface_hub import snapshot_download
from pathlib import Path
from langchain.text_splitter import CharacterTextSplitter




#fixed size chunking
def getFixedChunker(chunk_size,chunkCountSymbol=' '):
    splitter = CharacterTextSplitter(chunk_size = chunk_size, chunk_overlap=chunk_size*0.08, separator=chunkCountSymbol, strip_whitespace=False)
    #splitter.split_text("money money 1 2 3 4 5 6 7")
    return splitter

#semmantic splitting
def loadModel(modelName,modelPath,minChunkSize=400) -> text_splitter.SemanticChunker:
    
    model_kwargs = {"device": "cpu","trust_remote_code":True}
    encode_kwargs = {"normalize_embeddings": False}
    hf = HuggingFaceEmbeddings(
        model_name=(modelPath+modelName),
        model_kwargs=model_kwargs,
        encode_kwargs=encode_kwargs,
    )

    #passive use of model. CODE LOADS MODEL AND USES IT
    #splitter=text_splitter.SemanticChunker(embeddings=hf) 
    model=text_splitter.SemanticChunker(embeddings=hf,buffer_size=1, breakpoint_threshold_type="percentile", breakpoint_threshold_amount=93, min_chunk_size= minChunkSize)
    #model=text_splitter.SemanticChunker(embeddings=hf,buffer_size=1, breakpoint_threshold_type="standard_deviation", breakpoint_threshold_amount=0.75)
    #model=text_splitter.SemanticChunker(embeddings=hf,buffer_size=1, breakpoint_threshold_type="interquartile", breakpoint_threshold_amount=2)

    return model

def downloadModel(modelName,folderPath="./../models/"):

    dir =Path(folderPath+modelName)
    #hf_hub_download(repo_id=modelName,local_dir=folderPath)
    if not dir.is_dir():
        snapshot_download(repo_id=modelName,local_dir=(folderPath + modelName))

def getModel(modelName,minChunkSize=400):
    downloadModel(modelName)
    mod=loadModel(modelName=modelName,modelPath="./../models/",minChunkSize=minChunkSize)
    return mod


#for qdrant
def getEmbeddings(modelPath,modelName):
    model_kwargs = {"device": "cpu","trust_remote_code":True}
    encode_kwargs = {"normalize_embeddings": False}
    hf = HuggingFaceEmbeddings(
        model_name=(modelPath+modelName),
        model_kwargs=model_kwargs,
        encode_kwargs=encode_kwargs,
    )

def test():
    #Sentence Transformers and Universal Sentence Encoders are two different things!: https://milvus.io/ai-quick-reference/what-is-the-difference-between-sentence-transformers-and-other-sentence-embedding-methods-like-the-universal-sentence-encoder
    #encoders and embedders: https://medium.com/@sharifghafforov00/understanding-encoders-and-embeddings-in-large-language-models-llms-1e81101b2f87
    
    #you can also load models and save them like this. not recommended in my opinion. rather do it through cli hf tool
    #model =SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
    #model.save("/home/luke-weiss/dev/team_project/all-MiniLM-L6-v2",model_name="all-MiniLM-L6-v2")
    #model.encode(fullText) #active use of model. YOU USE THE MODEL!




    #testing - remove later
    #hf download --local-dir all-MiniLM-L6-v2 sentence-transformers/all-MiniLM-L6-v2
    #hf download --local-dir all-mpnet-base-v2 sentence-transformers/all-mpnet-base-v2
    #hf download --local-dir all-MiniLM-L12-v2 sentence-transformers/all-MiniLM-L12-v2
    fullText="Abstractâ€”Intrusion Detection System (IDS) is the key technology to ensure the security of dynamic systems. We employ a sequential pattern mining approach to discover significant system call sequences to prevent malicious attacks. To reduce the computing time of generating meaningful rules, we design a weighted suffix tree structure to detect intrusive events on the fly. The experimental results show our method can substantially enhance the accuracy and efficiency of IDS. I. INTRODUCTION An intrusion is defined as â€any set of actions that attempt to compromise the integrity, confidentiality or availability of a resourceâ€ [5]. Many intrusion prevention techniques, such as user authentication, information protection and programming errors avoidance, have been used to protect information systems from being intruded. With the increasing usage rate of computer users and the Internet, many malicious users and sophisticated hackers attempt to attack computer systems and grab private information. Intrusion detection system, therefore, has become an important solution to enhance the security of information systems. An IDS can detect and report intrusions to an operator but not prevent it. It can be divided into two types: centralized IDS which is performed on a single machine, and distributed IDS which is performed on multiple machines. Furthermore, IDS can be host-based or network-based; the former monitors activities on a single computer and the latter monitors activities over a network. All IDSs consist of three parts: data collection, data classification and data reporting. The data collection tasks collect several types of data: âˆ™ Network data âˆ™ System calls of operating system âˆ™ Command line of operating system âˆ™ Codes within applications âˆ™ All characters transmitted âˆ™ Keystrokes The network data comprises many features which can be analyzed; however, it is always encrypted for information privacy. To analyze the application is difficult because most of the source codes are not released. Unlike the aforementioned data types, the collection of system calls is not affected by data encryption, programming languages and operating systems. We can get system calls easily by monitoring operating system. The advantages of utilizing system calls as dataset, therefore, motivate us to develop a new IDS based on it. The data classification tasks can be divided into two categories [2], depending on whether researchers look for known intrusion signatures (misuse intrusion detection) [8][9][10][11] or anomalous behavior (anomaly intrusion detection) [19][27]. A misuse-based IDS requires prior knowledge of the intrusion, and they use these intrusion signatures to detect the occurrence of intrusion. By contrast, an anomaly-based IDS assumes that the intrusion behavior is unknown, but it is different from the behaviors of normal usage. The data reporting tasks inform system administrators when the anomalous or intrusive behaviors happened. In this paper, we design a weighted suffix tree structure together with sequential pattern mining method to discover meaningful sequential intrusion patterns for protecting malicious attacks in information systems. II. RELATED WORK A. Data Mining Data mining, also called Knowledge-Discovery in Database (KDD), is the process of automatically discovering unknown, implicit and meaningful patterns from large volumes of data. Many previous researchers applied typical data mining approaches to reveal specialized abnormal patterns [4][6][13]. Lee et al. used various kinds of mining-based model to improve IDS [12][15][16][17][18][22]. Li and Pan [14] proposed a ğœ™-association rule mining model based on FP-tree structure to improve the effectiveness of IDS. Xu and Gu [26] utilized the Apriori algorithm [1] to mine malicious attacks. The aforementioned research focus on finding nonsequential system call patterns instead of considering the sequence between system calls. In this paper, we concern the sequence between ordered system calls and extract significant sequential abnormal patterns for IDS. B. Suffix Tree A suffix tree is an edge-labeled compact tree with n leaves introduced by Weiner [24]. Many researchers proposed simplified methods to suffix tree construction [20][23]. Now, we illustrate a basic suffix tree structure through an example. Without loss of generality, we assume that the string S of length 5 is {03, 01, 03, 01, 15} and consequently were the suffixes of S which are {03, 01, 03, 01, 15}, {01, 03, 01, 15}, {03, 01, 15}, {01, 15}, {15}. We could find all suffixes of S showed in Fig. 1. III. SYSTEM ARCHITECTURE The overall system framework is developed to support a sequential mining-based IDS. It can strengthen the security of information systems, and it allows users to prevent malicious attacks. The system architecture is shown in Fig. 2, and it mainly consists of four parts: weighted suffix tree construction model, sequential pattern mining model, rule set pool and the decision engine. Functionalities of each component are described as follows. Weighted suffix tree construction model is used to store all sequences of system calls effectively and efficiently for further computation. We develop a new suffix tree structure to store the occurrences of all system calls which can avoid repetitively reconstructing suffix tree. After constructing weighted suffix tree, the sequential pattern mining model generates time-ordered system call patterns, and moves these possible malicious patterns into a rule set pool. We utilize the rule set pool to create a training model in the decision engine, therefore, once a malicious attack occurs, we can detect and report the intrusive event immediately. IV. METHODOLOGY A. Problem Formulation Definition 1: A set of system calls which are arranged in time order is called a â€system call sequenceâ€ [7][15]. Fig. 3. Weighted suffix tree after inserting < 03(1), 01(1), 15(1) >. Definition 2: A list of system calls issued by a single process from the beginning of its execution to the end is called â€traceâ€ [25]. B. Weighted Suffix Tree We propose a novel weighted suffix tree structure which is an extended suffix tree structure to store sequential system calls efficiently and to prevent repetitively suffix tree construction. The weighted suffix tree structure is capable of simultaneously storing multiple system call sequences. After the construction of the weighted suffix tree, we could calculate the frequent episodes through the statistics information of the nodes. We give an example to illustrate the process of weighted suffix tree construction. Assuming we have two sequences ğ‘†1 and ğ‘†2 in dataset D. D = {ğ‘†1, ğ‘†2}, ğ‘†1 = {03, 01, 03, 01, 15} and ğ‘†2 = {01, 01, 03, 01}. The weighted suffix tree is constructed as follows: 1. The root of tree is created and labeled with â€nullâ€. 2. Inserting each sequence into the suffix tree, e.g. ğ‘†1: < 03(1), 01(1), 03(1), 01(1), 15(1) > leads to the construction of the first branch of the tree, and the suffix of ğ‘†1: < 01(1), 03(1), 01(1), 15(1) > leads to the construction of the second branch of the tree. 3. If a sequence < 03(1), 01(1), 15(1) > shares a common prefix < 03(1), 01(1) > with the existed branch < 03(1), 01(1), 03(1), 01(1), 15(1) >, the weight of each node with a common prefix is incremented by 1, and a new node 15(1) is created as a child of node 01(1). The result after inserting < 03(1), 01(1), 15(1) > is shown in Fig. 3. 4. Repeating the above steps, we can construct a weighted suffix tree. Fig. 4 shows the result after processing sequence ğ‘†1 and ğ‘†2. We record the traversed number of each node when we built the tree. For example, the rightmost node of weighted suffix tree in Fig. 4 is noted as 15(1). The number 15 means the system call ID of that node, and the number 1 surrounded by parentheses means the traversed frequency of that node. The weighted suffix tree construction algorithm is described in Fig. 5 C. Frequent Episodes Mining Mannila et al. proposed a frequent episodes mining algorithm [21] which is an extension of association rules. A frequent episode is a set of items that occur frequently within a time window of a specified length. We give a brief example to explain the rule of frequent episode used in our research below: 03, 01 â†’ 03[ğ‘ ğ‘¢ğ‘ = 20%, ğ‘ğ‘œğ‘›ğ‘“ = 50%, ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„ = 3] A support of 20% for frequent episode rules means that 20% of all sequences with length 3 under analysis show that system call 03, 01, 03 are used in time order and appeared together. A confidence of 50% means that 50% of the system calls that system call 03, 01 appeared in order and system call 03 also appeared subsequently. We show the definition of support and confidence used in this paper below: ğ‘†ğ‘¢ğ‘ = Fig. 6. Frequent episodes mining algorithm. ğ‘‡ â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘ ğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ ğ‘†ğ‘¢ğ‘š ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ ğ‘œğ‘“ ğ‘ğ‘™ğ‘™ ğ‘ ğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ğ‘  ğ¶ğ‘œğ‘›ğ‘“ = ğ‘‡ â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘ ğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ ğ‘†ğ‘¢ğ‘š ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘ğ‘›ğ‘‘ ğ‘ ğ‘–ğ‘ğ‘™ğ‘–ğ‘›ğ‘”ğ‘  ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ The frequent episodes mining algorithm described in Fig. 6 is exploited to extract the rule sets with different length after the weighted suffix tree has been constructed. In the past, much research had troubles choosing the most appropriate length of sequential system calls for mining. They must run simulations to get the appropriate length of system call sequences, and repeatedly read whole traces when they need to collect other rule sets with other lengths of sequential system calls [7][15]. However, through our proposed weighted suffix tree, we can read the whole traces once instead of reading them many times while discovering different length of system call sequences. D. Intrusion Detection Model The t-stide method is a well known sequential-based technique proposed by C. Warrender et al. [25]. We apply t-stide method to verify whether intrusive events occur or not, and set a threshold to prune rare sequences which are regarded as abnormal patterns. We choose sup and conf defined by above section as threshold conditions in t-stide method. We, then, collect all frequent sequences of length k which are greater than or equal to the threshold and store them together for further usage. Finally, the decision engine compares the traces with the rule set, and reports the abnormal events to the user interface when mismatch rate exceeds the threshold. V. EXPERIMENTAL RESULTS We utilize different kinds of datasets provided by University of New Mexico [3] to evaluate the execution time and accurate rate of our methodology. We use 80% of normal traces to generate rule sets with different lengths, and the rest 20% of normal traces are used for testing. There are three sscp (sunsendmail) attack traces, two decode attack traces, and five error condition-forwarding loops attack traces for testing. Fig. 7 and Fig. 8 show the performance between the weighted suffix tree and non-weighted suffix tree of maximum sequences with different length. Fig. 7 provides data on the construction time, and it is apparent from the information supplied that the construction time of the weighted suffix tree is significantly less than non-weighted suffix tree. The  results reflected in Fig. 7 indicate that the weighted suffix tree structure can store all different length of sequences, and it can apparently reduce the cost of reconstructing a suffix tree. The mining time of generating abnormal patterns is given in Fig. 8, and it highlights differences between the two treebased structures. As observed in Fig. 8, the performance of using weighted suffix tree is better than non-weighted suffix tree. A glance at the two tables provided reveals the experimental results using the rules with length 5 and length 7. The first row of Table I and Table II is the experimental results running with the method proposed by Warrender et al. [25]. The column of normal abn% means the mismatch rate of normal traces. We also record the mismatch rate of the sscp (sunsendmailcp), the decode, and the fwd (forwarding loops). In Table I, we use the method proposed by [25] to generate 660 rules, and the mismatch rate of normal traces, sscp, decode, and fwd are 3.3%, 16.5%, 5.9%, and 13.9%, respectively. Hence the minimum gap of mismatch rate between normal traces and abnormal traces is 2.6%. After we simulate the experiments with different support and confidence thresholds, we observe that the number of rules generated by our methodology is less than Warrender et al. [25]. The phenomenon indicates that the decision engine of IDS is faster than it does before [25]. By contrast, the mismatch rate of normal traces is higher than the method of [25]. On the other hand, the mismatch rate of abnormal traces will also be higher than the method of [25]. From Table I and Table II, it is evident that the gap generated by our methodology is larger than original method, and it help us to prove that the decision engine can explicitly recognize which trace is normal or abnormal. VI. CONCLUSIONS IDS is a technique which is proposed to improve the security of computer system, and it needs to process a lot of data sets to carry on analysis. This characteristic makes the application of data mining an important role in IDS. Much research apply data mining to support IDS, but they just only find frequent patterns without concerning the order between system calls. In this paper, we develop a feasible suffix treebased data structure to mine time-ordered patterns. From the experimental results, it is evident that our methodology can reduce the construction time of multiple system call sequences, and shorten the mining time of generating sequential patterns. The experimental results also show that the gap between the mismatch rate of normal traces and the mismatch rate of abnormal traces is large. It means that our methodology can help IDS to definitely recognize intrusive events. ACKNOWLEDGMENT This research was sponsored by National Science Council, Taiwan under the grant 99-2219-E-002-021."
    #fullText="You better not lose it! The money is in the bag! By programmers do you mean hobbyists/students or do you mean professionals on the job? Hobbyists/students have difficulty learning things. Maybe they didn't pay attention or care during a databases/SQL class or maybe they had to do a bug fix in a codebase for a homework assignment and couldn't figure out how to do it. Those previous two sentences describe things that happened when I was getting my Computer Science degree. Oh, also I had issues with teamwork and cooperation with others on a team project. Teamwork is very important in the real world, professional software developers usually work in teams. Professionals on the job have to learn things too just like students do but they also have other difficulties. Professional programmers usually work in teams on a codebase that was created before they joined the team. The codebase can be massive, maybe millions of lines of code. They have to make bug fixes in that code and add features to it, and in order for them to be able to do that they must be able to read and understand the code. Reading and understanding code that other people wrote is really hard. I personally have more difficulty doing that than writing my own code by myself from scratch. Each codebase has its own structure and architecture that you must learn. Hopefully there is a senior (like 5+ years of experience) or staff/principal (like 10+ years of experience) developer who can explain it to you and maybe show you some pre-recorded video or documentation detailing and explaining the codebase. A codebase for work can take four months to two years to learn, depending on the codebase. There is a lot of code in a codebase. So yeah, that's a big problem. You have to make bug fixes and add features in that massive, hard to understand mess of code. Most beginners and newcomers think the code is a mess that is impossible to understand when they start, and their natural inclination is to want to rewrite everything from scratch in a way that they fully understand. A full rewrite is usually a bad idea even though you may feel you want to do it. A codebase that looks like an impossible to understand mess to you may make perfect sense and be easy to navigate to the person who initially created it and built it out from the beginning. It is better if this person with experience teaches you the codebase. It takes time to learn a codebase, and often the person paying you doesn't want to spend the time training you. Usually the person paying you just wants to see results for their money ASAP. There is this expression adding more new people to a late software project makes it later. The new people need to learn the codebase and be trained by the old people, and doing so takes time away from the old people that they could be spending working on the codebase. Often the person paying and hiring wants to speed up development by hiring more people, but the new people need to learn and be trained and that takes time. It is better to hire more people than you need early and fire off the people who suck or are bad at learning then it is to try to frantically hire and train people later on. The fact that the people paying money or hiring don't want to train makes it hard for newcomers with no experience (i.e. freshers) to enter the job market and become junior developers, which is the title people get when they have like 0-2 years of experience (it's basically an on-the-job apprenticeship where your mentor is a senior developer). Newcomers fresh out of school take more time to learn the ropes than people who have been doing the same job for years (i.e. senior developers). Junior developers need more ramp-up time, and employers don't want to pay for ramp-up time. For this reason, usually the first one or two coding jobs are the hardest for a computer science person to get. After they have the work experience, it's usually a lot easier to get a job but employers give them less ramp-up time then when they were first starting out. So getting your first programming job is a big problem for hobbyists/students and then after that the ramp-up is a big problem. Some people are slow at ramp-up and employers are impatient and they just fire off the slow people. Eventually people who are very slow keep getting fired and end up having to find a different industry. I was very bad at ramp-up and ultimately ended up unemployed and then on government disability benefits. So yeah, I would say the most common problems are getting your first job and the ramp-up. Learning technical stuff like programming languages and frameworks is a problem for some people but me personally, I used to enjoy reading books on that stuff that I bought off of Amazon before bed so that wasn't my main problem. Like if I needed to learn C I would read The C Programming Language book before bed or if I needed to learn Node.js I would read a book on that before bed and in general that combined with some time Googling and reading documentation on the job was enough. Once you learn a few programming languages, learning a new one isnt a problem and once you learn a few web frameworks like Node.js , Spring Boot, Django, Ruby on Rails, and so forth then learning an additional one isn't a problem. Hobbyists/students have some difficulty learning their first framework but for people with experience learning a new one isn't a problem. As for solutions, I dunno. It's hard to predict how good someone will be at a job before they spend time trying to do the job. There is a minimum barrier to entry but above that it is hard to predict. These problems like teamwork and ramp-up are systemic things and there isn't an easy fix. Like maybe if people were more intelligent or had more talent ramp-up would be easier. Some people have personality disorders like Narcissistic Personality Disorder which make teamwork with them difficult. There isn't an easy fix for these things. Edit: Another person replied Managers who dont understand what they want, what they need, and what is not possible. At Amazon I was blessed with a good, organized manager with technical skills so I didn't have the problem of a manager who didn't know what is not technically possible, but if your manager can't read or write code and has never built a code project himself then you can run into this issue."


    modeln=["sentence-transformers/msmarco-MiniLM-L12-v3","sentence-transformers/embeddinggemma-300m-medical","sentence-transformers/all-MiniLM-L6-v2","sentence-transformers/all-MiniLM-L12-v2","sentence-transformers/all-mpnet-base-v2"]
    #sentence-transformers/embeddinggemma-300m-medical
    path="./models/"

    mod=modeln[1]
    downloadModel(mod)

    mod1=loadModel(modelName=mod,modelPath=path)
    #mod1=getFixedChunker(800)


    #mod=getFixedChunker(350,' ')
    #chunks=mod.create_documents(fullText)
    chunks1=splitText(mod1,fullText)


    for i in chunks1:
        print()
        print(i)



def splitText(splitterModel,text) -> List[str]:
    chunks=splitterModel.split_text(text)
    return chunks

#dont use
def intersection(chunk1,chunk2):
    index1=[chunk1]
    index2=[chunk2]
    ret=[]

    temp=0
    for i in range(len(chunk1)):
        index1[i]=len(chunk1[i])+temp
        temp=index1[i]

    for i in range(len(chunk2)):
        index2[i]=len(chunk2[i])+temp
        temp=index2[i]

    inx=0
    cloIndex=0

    miC=min(len(chunk1),len(chunk2))


    for i in range(miC):
        a=0
        b=0
        print(chunk1[i])
        if index1[i+a] <index2[i+b]- len(chunk2[i+b]):
            a=a+1
        elif index1[i+a] - len(chunk1[i+a])>index2[i+b]:
            b=b+1


        inter=(index1[i+a]+index2[i+b])/2
        mi=min(index1[i+a],index2[i+b])
        ma=max(index1[i+a],index2[i+b])

        if mi -inter< inter -ma:
            cloIndex=mi
        else:
            cloIndex=ma


        if cloIndex == index1:
            ret[i]=chunk1[i+a][inx:]
        else:
            ret[i]=chunk2[i+b][inx:]

        inx=cloIndex

    if miC==chunk1:
        ret= ret + chunk1[miC:]
    else:
        ret= ret + chunk2[miC:]

    return ret

    #if index1<index2:
    #    
    #    if index1-inter<inter-index2
    #        cloIndex=index1
    #        cloText=chunk1
    #        ret[0]=chunk1[][inx:]
    #        inx=index1
    #else:
    #    if index1-inter>inter-index2
    #        cloIndex=index1
    #        cloText=chunk1
    #        ret[0]=chunk2[][inx:]
    #        inx=index2




if __name__ == '__main__':
    
    
    fullText="Abstractâ€”Intrusion Detection System (IDS) is the key technology to ensure the security of dynamic systems. We employ a sequential pattern mining approach to discover significant system call sequences to prevent malicious attacks. To reduce the computing time of generating meaningful rules, we design a weighted suffix tree structure to detect intrusive events on the fly. The experimental results show our method can substantially enhance the accuracy and efficiency of IDS. I. INTRODUCTION An intrusion is defined as â€any set of actions that attempt to compromise the integrity, confidentiality or availability of a resourceâ€ [5]. Many intrusion prevention techniques, such as user authentication, information protection and programming errors avoidance, have been used to protect information systems from being intruded. With the increasing usage rate of computer users and the Internet, many malicious users and sophisticated hackers attempt to attack computer systems and grab private information. Intrusion detection system, therefore, has become an important solution to enhance the security of information systems. An IDS can detect and report intrusions to an operator but not prevent it. It can be divided into two types: centralized IDS which is performed on a single machine, and distributed IDS which is performed on multiple machines. Furthermore, IDS can be host-based or network-based; the former monitors activities on a single computer and the latter monitors activities over a network. All IDSs consist of three parts: data collection, data classification and data reporting. The data collection tasks collect several types of data: âˆ™ Network data âˆ™ System calls of operating system âˆ™ Command line of operating system âˆ™ Codes within applications âˆ™ All characters transmitted âˆ™ Keystrokes The network data comprises many features which can be analyzed; however, it is always encrypted for information privacy. To analyze the application is difficult because most of the source codes are not released. Unlike the aforementioned data types, the collection of system calls is not affected by data encryption, programming languages and operating systems. We can get system calls easily by monitoring operating system. The advantages of utilizing system calls as dataset, therefore, motivate us to develop a new IDS based on it. The data classification tasks can be divided into two categories [2], depending on whether researchers look for known intrusion signatures (misuse intrusion detection) [8][9][10][11] or anomalous behavior (anomaly intrusion detection) [19][27]. A misuse-based IDS requires prior knowledge of the intrusion, and they use these intrusion signatures to detect the occurrence of intrusion. By contrast, an anomaly-based IDS assumes that the intrusion behavior is unknown, but it is different from the behaviors of normal usage. The data reporting tasks inform system administrators when the anomalous or intrusive behaviors happened. In this paper, we design a weighted suffix tree structure together with sequential pattern mining method to discover meaningful sequential intrusion patterns for protecting malicious attacks in information systems. II. RELATED WORK A. Data Mining Data mining, also called Knowledge-Discovery in Database (KDD), is the process of automatically discovering unknown, implicit and meaningful patterns from large volumes of data. Many previous researchers applied typical data mining approaches to reveal specialized abnormal patterns [4][6][13]. Lee et al. used various kinds of mining-based model to improve IDS [12][15][16][17][18][22]. Li and Pan [14] proposed a ğœ™-association rule mining model based on FP-tree structure to improve the effectiveness of IDS. Xu and Gu [26] utilized the Apriori algorithm [1] to mine malicious attacks. The aforementioned research focus on finding nonsequential system call patterns instead of considering the sequence between system calls. In this paper, we concern the sequence between ordered system calls and extract significant sequential abnormal patterns for IDS. B. Suffix Tree A suffix tree is an edge-labeled compact tree with n leaves introduced by Weiner [24]. Many researchers proposed simplified methods to suffix tree construction [20][23]. Now, we illustrate a basic suffix tree structure through an example. Without loss of generality, we assume that the string S of length 5 is {03, 01, 03, 01, 15} and consequently were the suffixes of S which are {03, 01, 03, 01, 15}, {01, 03, 01, 15}, {03, 01, 15}, {01, 15}, {15}. We could find all suffixes of S showed in Fig. 1. III. SYSTEM ARCHITECTURE The overall system framework is developed to support a sequential mining-based IDS. It can strengthen the security of information systems, and it allows users to prevent malicious attacks. The system architecture is shown in Fig. 2, and it mainly consists of four parts: weighted suffix tree construction model, sequential pattern mining model, rule set pool and the decision engine. Functionalities of each component are described as follows. Weighted suffix tree construction model is used to store all sequences of system calls effectively and efficiently for further computation. We develop a new suffix tree structure to store the occurrences of all system calls which can avoid repetitively reconstructing suffix tree. After constructing weighted suffix tree, the sequential pattern mining model generates time-ordered system call patterns, and moves these possible malicious patterns into a rule set pool. We utilize the rule set pool to create a training model in the decision engine, therefore, once a malicious attack occurs, we can detect and report the intrusive event immediately. IV. METHODOLOGY A. Problem Formulation Definition 1: A set of system calls which are arranged in time order is called a â€system call sequenceâ€ [7][15]. Fig. 3. Weighted suffix tree after inserting < 03(1), 01(1), 15(1) >. Definition 2: A list of system calls issued by a single process from the beginning of its execution to the end is called â€traceâ€ [25]. B. Weighted Suffix Tree We propose a novel weighted suffix tree structure which is an extended suffix tree structure to store sequential system calls efficiently and to prevent repetitively suffix tree construction. The weighted suffix tree structure is capable of simultaneously storing multiple system call sequences. After the construction of the weighted suffix tree, we could calculate the frequent episodes through the statistics information of the nodes. We give an example to illustrate the process of weighted suffix tree construction. Assuming we have two sequences ğ‘†1 and ğ‘†2 in dataset D. D = {ğ‘†1, ğ‘†2}, ğ‘†1 = {03, 01, 03, 01, 15} and ğ‘†2 = {01, 01, 03, 01}. The weighted suffix tree is constructed as follows: 1. The root of tree is created and labeled with â€nullâ€. 2. Inserting each sequence into the suffix tree, e.g. ğ‘†1: < 03(1), 01(1), 03(1), 01(1), 15(1) > leads to the construction of the first branch of the tree, and the suffix of ğ‘†1: < 01(1), 03(1), 01(1), 15(1) > leads to the construction of the second branch of the tree. 3. If a sequence < 03(1), 01(1), 15(1) > shares a common prefix < 03(1), 01(1) > with the existed branch < 03(1), 01(1), 03(1), 01(1), 15(1) >, the weight of each node with a common prefix is incremented by 1, and a new node 15(1) is created as a child of node 01(1). The result after inserting < 03(1), 01(1), 15(1) > is shown in Fig. 3. 4. Repeating the above steps, we can construct a weighted suffix tree. Fig. 4 shows the result after processing sequence ğ‘†1 and ğ‘†2. We record the traversed number of each node when we built the tree. For example, the rightmost node of weighted suffix tree in Fig. 4 is noted as 15(1). The number 15 means the system call ID of that node, and the number 1 surrounded by parentheses means the traversed frequency of that node. The weighted suffix tree construction algorithm is described in Fig. 5 C. Frequent Episodes Mining Mannila et al. proposed a frequent episodes mining algorithm [21] which is an extension of association rules. A frequent episode is a set of items that occur frequently within a time window of a specified length. We give a brief example to explain the rule of frequent episode used in our research below: 03, 01 â†’ 03[ğ‘ ğ‘¢ğ‘ = 20%, ğ‘ğ‘œğ‘›ğ‘“ = 50%, ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„ = 3] A support of 20% for frequent episode rules means that 20% of all sequences with length 3 under analysis show that system call 03, 01, 03 are used in time order and appeared together. A confidence of 50% means that 50% of the system calls that system call 03, 01 appeared in order and system call 03 also appeared subsequently. We show the definition of support and confidence used in this paper below: ğ‘†ğ‘¢ğ‘ = Fig. 6. Frequent episodes mining algorithm. ğ‘‡ â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘ ğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ ğ‘†ğ‘¢ğ‘š ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ ğ‘œğ‘“ ğ‘ğ‘™ğ‘™ ğ‘ ğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ğ‘  ğ¶ğ‘œğ‘›ğ‘“ = ğ‘‡ â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘ ğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘’ ğ‘†ğ‘¢ğ‘š ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ ğ‘ğ‘›ğ‘‘ ğ‘ ğ‘–ğ‘ğ‘™ğ‘–ğ‘›ğ‘”ğ‘  ğ‘œğ‘“ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘ ğ‘¡ ğ‘›ğ‘œğ‘‘ğ‘’ The frequent episodes mining algorithm described in Fig. 6 is exploited to extract the rule sets with different length after the weighted suffix tree has been constructed. In the past, much research had troubles choosing the most appropriate length of sequential system calls for mining. They must run simulations to get the appropriate length of system call sequences, and repeatedly read whole traces when they need to collect other rule sets with other lengths of sequential system calls [7][15]. However, through our proposed weighted suffix tree, we can read the whole traces once instead of reading them many times while discovering different length of system call sequences. D. Intrusion Detection Model The t-stide method is a well known sequential-based technique proposed by C. Warrender et al. [25]. We apply t-stide method to verify whether intrusive events occur or not, and set a threshold to prune rare sequences which are regarded as abnormal patterns. We choose sup and conf defined by above section as threshold conditions in t-stide method. We, then, collect all frequent sequences of length k which are greater than or equal to the threshold and store them together for further usage. Finally, the decision engine compares the traces with the rule set, and reports the abnormal events to the user interface when mismatch rate exceeds the threshold. V. EXPERIMENTAL RESULTS We utilize different kinds of datasets provided by University of New Mexico [3] to evaluate the execution time and accurate rate of our methodology. We use 80% of normal traces to generate rule sets with different lengths, and the rest 20% of normal traces are used for testing. There are three sscp (sunsendmail) attack traces, two decode attack traces, and five error condition-forwarding loops attack traces for testing. Fig. 7 and Fig. 8 show the performance between the weighted suffix tree and non-weighted suffix tree of maximum sequences with different length. Fig. 7 provides data on the construction time, and it is apparent from the information supplied that the construction time of the weighted suffix tree is significantly less than non-weighted suffix tree. The  results reflected in Fig. 7 indicate that the weighted suffix tree structure can store all different length of sequences, and it can apparently reduce the cost of reconstructing a suffix tree. The mining time of generating abnormal patterns is given in Fig. 8, and it highlights differences between the two treebased structures. As observed in Fig. 8, the performance of using weighted suffix tree is better than non-weighted suffix tree. A glance at the two tables provided reveals the experimental results using the rules with length 5 and length 7. The first row of Table I and Table II is the experimental results running with the method proposed by Warrender et al. [25]. The column of normal abn% means the mismatch rate of normal traces. We also record the mismatch rate of the sscp (sunsendmailcp), the decode, and the fwd (forwarding loops). In Table I, we use the method proposed by [25] to generate 660 rules, and the mismatch rate of normal traces, sscp, decode, and fwd are 3.3%, 16.5%, 5.9%, and 13.9%, respectively. Hence the minimum gap of mismatch rate between normal traces and abnormal traces is 2.6%. After we simulate the experiments with different support and confidence thresholds, we observe that the number of rules generated by our methodology is less than Warrender et al. [25]. The phenomenon indicates that the decision engine of IDS is faster than it does before [25]. By contrast, the mismatch rate of normal traces is higher than the method of [25]. On the other hand, the mismatch rate of abnormal traces will also be higher than the method of [25]. From Table I and Table II, it is evident that the gap generated by our methodology is larger than original method, and it help us to prove that the decision engine can explicitly recognize which trace is normal or abnormal. VI. CONCLUSIONS IDS is a technique which is proposed to improve the security of computer system, and it needs to process a lot of data sets to carry on analysis. This characteristic makes the application of data mining an important role in IDS. Much research apply data mining to support IDS, but they just only find frequent patterns without concerning the order between system calls. In this paper, we develop a feasible suffix treebased data structure to mine time-ordered patterns. From the experimental results, it is evident that our methodology can reduce the construction time of multiple system call sequences, and shorten the mining time of generating sequential patterns. The experimental results also show that the gap between the mismatch rate of normal traces and the mismatch rate of abnormal traces is large. It means that our methodology can help IDS to definitely recognize intrusive events. ACKNOWLEDGMENT This research was sponsored by National Science Council, Taiwan under the grant 99-2219-E-002-021."
    #fullText="You better not lose it! The money is in the bag! By programmers do you mean hobbyists/students or do you mean professionals on the job? Hobbyists/students have difficulty learning things. Maybe they didn't pay attention or care during a databases/SQL class or maybe they had to do a bug fix in a codebase for a homework assignment and couldn't figure out how to do it. Those previous two sentences describe things that happened when I was getting my Computer Science degree. Oh, also I had issues with teamwork and cooperation with others on a team project. Teamwork is very important in the real world, professional software developers usually work in teams. Professionals on the job have to learn things too just like students do but they also have other difficulties. Professional programmers usually work in teams on a codebase that was created before they joined the team. The codebase can be massive, maybe millions of lines of code. They have to make bug fixes in that code and add features to it, and in order for them to be able to do that they must be able to read and understand the code. Reading and understanding code that other people wrote is really hard. I personally have more difficulty doing that than writing my own code by myself from scratch. Each codebase has its own structure and architecture that you must learn. Hopefully there is a senior (like 5+ years of experience) or staff/principal (like 10+ years of experience) developer who can explain it to you and maybe show you some pre-recorded video or documentation detailing and explaining the codebase. A codebase for work can take four months to two years to learn, depending on the codebase. There is a lot of code in a codebase. So yeah, that's a big problem. You have to make bug fixes and add features in that massive, hard to understand mess of code. Most beginners and newcomers think the code is a mess that is impossible to understand when they start, and their natural inclination is to want to rewrite everything from scratch in a way that they fully understand. A full rewrite is usually a bad idea even though you may feel you want to do it. A codebase that looks like an impossible to understand mess to you may make perfect sense and be easy to navigate to the person who initially created it and built it out from the beginning. It is better if this person with experience teaches you the codebase. It takes time to learn a codebase, and often the person paying you doesn't want to spend the time training you. Usually the person paying you just wants to see results for their money ASAP. There is this expression adding more new people to a late software project makes it later. The new people need to learn the codebase and be trained by the old people, and doing so takes time away from the old people that they could be spending working on the codebase. Often the person paying and hiring wants to speed up development by hiring more people, but the new people need to learn and be trained and that takes time. It is better to hire more people than you need early and fire off the people who suck or are bad at learning then it is to try to frantically hire and train people later on. The fact that the people paying money or hiring don't want to train makes it hard for newcomers with no experience (i.e. freshers) to enter the job market and become junior developers, which is the title people get when they have like 0-2 years of experience (it's basically an on-the-job apprenticeship where your mentor is a senior developer). Newcomers fresh out of school take more time to learn the ropes than people who have been doing the same job for years (i.e. senior developers). Junior developers need more ramp-up time, and employers don't want to pay for ramp-up time. For this reason, usually the first one or two coding jobs are the hardest for a computer science person to get. After they have the work experience, it's usually a lot easier to get a job but employers give them less ramp-up time then when they were first starting out. So getting your first programming job is a big problem for hobbyists/students and then after that the ramp-up is a big problem. Some people are slow at ramp-up and employers are impatient and they just fire off the slow people. Eventually people who are very slow keep getting fired and end up having to find a different industry. I was very bad at ramp-up and ultimately ended up unemployed and then on government disability benefits. So yeah, I would say the most common problems are getting your first job and the ramp-up. Learning technical stuff like programming languages and frameworks is a problem for some people but me personally, I used to enjoy reading books on that stuff that I bought off of Amazon before bed so that wasn't my main problem. Like if I needed to learn C I would read The C Programming Language book before bed or if I needed to learn Node.js I would read a book on that before bed and in general that combined with some time Googling and reading documentation on the job was enough. Once you learn a few programming languages, learning a new one isnt a problem and once you learn a few web frameworks like Node.js , Spring Boot, Django, Ruby on Rails, and so forth then learning an additional one isn't a problem. Hobbyists/students have some difficulty learning their first framework but for people with experience learning a new one isn't a problem. As for solutions, I dunno. It's hard to predict how good someone will be at a job before they spend time trying to do the job. There is a minimum barrier to entry but above that it is hard to predict. These problems like teamwork and ramp-up are systemic things and there isn't an easy fix. Like maybe if people were more intelligent or had more talent ramp-up would be easier. Some people have personality disorders like Narcissistic Personality Disorder which make teamwork with them difficult. There isn't an easy fix for these things. Edit: Another person replied Managers who dont understand what they want, what they need, and what is not possible. At Amazon I was blessed with a good, organized manager with technical skills so I didn't have the problem of a manager who didn't know what is not technically possible, but if your manager can't read or write code and has never built a code project himself then you can run into this issue."


    modeln=["sentence-transformers/embeddinggemma-300m-medical","sentence-transformers/all-MiniLM-L6-v2","sentence-transformers/msmarco-MiniLM-L12-v3","sentence-transformers/all-MiniLM-L12-v2","sentence-transformers/all-mpnet-base-v2"]
    #sentence-transformers/embeddinggemma-300m-medical
    path="./models/"

    mod=modeln[0]
    downloadModel(mod)

    mod1=loadModel(modelName=mod,modelPath=path, minChunkSize=800)
    #mod1=getFixedChunker(800)


    #mod=getFixedChunker(350,' ')
    #chunks=mod.create_documents(fullText)
    chunks1=splitText(mod1,fullText)


    for i in chunks1:
        print()
        print(i)



    